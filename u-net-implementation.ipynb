{"cells":[{"metadata":{"_uuid":"d031ff62-564f-4e81-b7f6-e14d43edc786","_cell_guid":"f2806977-67da-4144-b25d-457a90e85bb7","trusted":true},"cell_type":"code","source":"# %% [code]\n!conda install pytorch torchvision -c pytorch --yes\n\n# %% [code]\nimport torch\nimport torch.nn as nn\n\n# %% [code]\n\n# inchannel and outchannel\n#2 3X3 unpadded convolutions which you see here\ndef double_conv(in_c, out_c):\n    conv=nn.Sequential(\n        nn.Conv2d(in_c, out_c, kernel_size=3),\n        nn.ReLU(inplace=True),#gets added here inplace\n        nn.Conv2d(out_c, out_c, kernel_size=3),\n        nn.ReLU(inplace=True),\n    )\n    return conv\n\n# %% [code]\ndef crop_img(tensor, target_tensor):\n    target_size = target_tensor.size()[2]\n    tensor_size = tensor.size()[2]\n    delta = tensor_size - target_size\n    delta = delta // 2\n    return tensor[:,:,delta:tensor_size - delta,delta:tensor_size - delta]\n\n\n# %% [code]\nclass Unet(nn.Module):#inherits from nn.module\n    #we increase channels in the first part\n    #In the second part we decrease channels\n    def __init__(self):\n        super(Unet,self).__init__()\n\n\n        self.max_pool_2X2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.down_conv_1 = double_conv(1, 64)\n        self.down_conv_2 = double_conv(64, 128)\n        self.down_conv_3 = double_conv(128, 256)\n        self.down_conv_4 = double_conv(256, 512)\n        self.down_conv_5 = double_conv(512, 1024)\n        \n        #Up transpose 1\n        self.up_trans_1 = nn.ConvTranspose2d(\n            in_channels=1024, \n            out_channels=512,\n            kernel_size=2,\n            stride=2)\n        \n        self.up_conv_1 = double_conv(1024, 512)\n\n        #Up transpose 2\n        self.up_trans_2 = nn.ConvTranspose2d(\n            in_channels=512, \n            out_channels=256,\n            kernel_size=2,\n            stride=2)\n        \n        self.up_conv_2 = double_conv(512, 256)\n\n        #Up transpose 3\n        self.up_trans_3 = nn.ConvTranspose2d(\n            in_channels=256, \n            out_channels=128,\n            kernel_size=2,\n            stride=2)\n        \n        self.up_conv_3 = double_conv(256, 128)\n        \n        #Up transpose 4\n        self.up_trans_4 = nn.ConvTranspose2d(\n            in_channels=128, \n            out_channels=64,\n            kernel_size=2,\n            stride=2)\n        \n        self.up_conv_4 = double_conv(128, 64)\n        \n        self.out = nn.Conv2d(\n        in_channels = 64,\n        out_channels = 2,\n        kernel_size=1)\n        #2d conv with a kernel_size of 1\n\n     \n    #Takes one image and runs the forward pass\n    def forward(self, image):\n        #bs,c,h,w : In forward pass expected size is batchsize, channel, height and width\n        #encoder\n        \n        x1 = self.down_conv_1(image) #\n        x2 = self.max_pool_2X2(x1)\n        #After each down_conv need to apply maxpooling\n        \n        x3 = self.down_conv_2(x2) #\n        x4 = self.max_pool_2X2(x3)\n        \n        x5 = self.down_conv_3(x4) #\n        x6 = self.max_pool_2X2(x5)\n        \n        x7 = self.down_conv_4(x6) #\n        x8 = self.max_pool_2X2(x7)\n        \n        x9 = self.down_conv_5(x8)\n        #Replace end\n        #decoder\n        x = self.up_trans_1(x9)\n        y = crop_img(x7,x)\n        x = self.up_conv_1(torch.cat([x, y], 1))#using y which is the cropped x7\n        \n        x = self.up_trans_2(x)\n        y = crop_img(x5,x)\n        x = self.up_conv_2(torch.cat([x, y], 1))\n        \n        x = self.up_trans_3(x)\n        y = crop_img(x3,x)\n        x = self.up_conv_3(torch.cat([x, y], 1))\n        \n        x = self.up_trans_4(x)\n        y = crop_img(x1,x)\n        x = self.up_conv_4(torch.cat([x, y], 1))\n        \n        x= self.out(x)\n        print(x.size())\n        return x\n\n# %% [code]\nif __name__ == '__main__':\n    image = torch.rand(1,1,572,572)\n    model = Unet()#initializing the model Unet\n    print(model(image))\n    #2 channels: 1 will be foreground and the other will be background\n    \n    ","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}